{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c70091-6c01-44ae-8b0b-04083bb881e3",
   "metadata": {},
   "source": [
    "## Part 1: HDFS Deployment and Data Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf092bc-ae7f-41bd-a706-cab9c153eecb",
   "metadata": {},
   "source": [
    "Plz do not modify the cells with labelled headers - e.g. 1.1, 2.6, 3.4, etc. They are there for both autograding and to provide sanity checks for you during devolpment. For all other cells, comments specify a few variables you need to use, but otherwise you are free to add new cells and modify the existing ones as desired :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0bcfb5-0527-4318-ab90-059464bdb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 - libs you will need\n",
    "import requests\n",
    "import time\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f870a-be55-4e7f-8d75-1b491e80c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - pwd test should return \"/notebooks\"\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca04ce7-8995-4f45-adac-142b82be4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 - docker test should return \"/usr/bin/sh: 1:  docker: not found\"\n",
    "!docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e0fd9-9569-4fe7-88bf-ac0d892db990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download hdma-wi-2021.csv\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c840262-bdc5-4211-bc83-ec2357aa670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - should show hdma-wi-2021.csv has been downloaded to the notebooks directory\n",
    "!ls -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15639b91-b394-4501-b844-95581bd15b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hdfs to upload hdma-wi-2021 as single.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6903e8fd-2b25-4b9b-b941-b29ef044eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hdfs to upload hdma-wi-2020 as double.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b71813-0cba-4250-b414-e37b049dd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 - Check that double.csv is twice the size of single.csv\n",
    "!hdfs dfs -du -h hdfs://main:9000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181f6ac-f215-4a38-bb63-60d2bdd47c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Check your block size - should return 1048576 Bytes aka ~1MB for both double.csv and single.csv\n",
    "!echo -n \"double.csv block size: \" && hdfs dfs -stat %o hdfs://main:9000/double.csv\n",
    "!echo -n \"single.csv block size: \" && hdfs dfs -stat %o hdfs://main:9000/single.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6c826-d02e-4c3d-bafe-b36a9b3e6c3c",
   "metadata": {},
   "source": [
    "## Part 2: Block Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac0969d-0ed6-4a14-ab2e-bc0a1896cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the dictonary per_worker_block_count_single_csv for your final counts\n",
    "# if you do not want to type such a long name, just use a shorter named dictonary for the counting\n",
    "# and then set per_worker_block_count_single_csv dict equal to your shorter dictonary.\n",
    "# e.g. per_worker_block_count_single_csv = my_dict\n",
    "\n",
    "per_worker_block_count_single_csv = {} # plz do not change the name of this dictonary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027839c-bf3e-42eb-89d5-593ecbe146ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 - while your block distribution may be different, your sum should be equal to 167 (think about why this is)\n",
    "per_worker_block_count_single_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca79cab-8cf1-410a-8299-9bfcd5630dc9",
   "metadata": {},
   "source": [
    "## Part 3: Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9bbcb-843c-4441-a2b6-c4b0151269fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class hdfsFile(io.RawIOBase):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.offset = 0\n",
    "        self.length = 0 # TODO\n",
    "    def readable(self):\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def readinto(self, b):\n",
    "        # TODO\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a4363-a593-46e8-ac93-78e01e0eaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the single_count and multi_count variables to keep track of how many lines\n",
    "# contain the text \"Single Family\" and how many contain \"Multifamily\". \n",
    "# Use t_start for the start time and t_end for the end time\n",
    "t_start = time.time()\n",
    "t_end = 0\n",
    "single_count = 0\n",
    "multi_count = 0\n",
    "bs_1 = -1\n",
    "\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size=bs_1):\n",
    "    # TODO\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5d9e5-62c5-4f53-8d0f-5dd97f5e672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "single_count # should return 444874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a599be5-ca2f-4728-9309-7ee6504413ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 \n",
    "multi_count # should return 2493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ceaa4-ebc9-426c-a217-39ad94292c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3\n",
    "t_end - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d429cf79-97cb-422a-ab6d-3069fe22c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your second buffer size here \n",
    "# pass them into your loop like so\n",
    "# for line in io.BufferedReader(hdfsFile(\"file.csv\"), buffer_size=bs_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384df10-b012-41cf-afe8-6c3435895a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the single_count and multi_count variables to keep track of how many lines\n",
    "# contain the text \"Single Family\" and how many contain \"Multifamily\". \n",
    "# Use t_start for the start time and t_end for the end time\n",
    "\n",
    "t_start = time.time()\n",
    "t_end = -1\n",
    "single_count = 0\n",
    "multi_count = 0\n",
    "bs_2 = 0\n",
    "\n",
    "\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size=bs_2):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34913d-7554-4dc5-8b7d-4507cba85dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4\n",
    "single_count # should return 444874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b15b1-d93c-4149-a088-6995e2f109f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5\n",
    "multi_count # should return 2493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6701573-350e-4cf6-9c2c-258dc9ae16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6\n",
    "t_end - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee4d3a-c9cf-46aa-b97b-d210ae72f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7\n",
    "bs_1, bs_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
